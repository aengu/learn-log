from groq import Groq
from tavily import TavilyClient
from django.conf import settings
from django.utils.text import slugify
from .models import LearningLog, Tag, Reference

"""
todo
- include_domain ìë™ ë³€ê²½
- groq temperature ìˆ˜ì¹˜ ì¡°ì •
- query ì§ˆì˜ í›„ progress bar + log
- ì°¸ê³ ìë£Œì— github ëº„ê¹Œ...
- íƒœê·¸ ê³„ì¸µí™” (ex: database-postgresql-isolation_level)
"""

class LearnlogService:
    """
    Learnlog ë¡œì§
    - Tavilyë¡œ ì›¹ ê²€ìƒ‰
    - Groqë¡œ AI ë‹µë³€ ìƒì„±
    - Groqë¡œ íƒœê·¸ ìë™ ì¶”ì¶œ
    - Groqë¡œ ë§ˆí¬ë‹¤ìš´ ë³€í™˜
    """
    
    def __init__(self):
        self.groq_client = Groq(api_key=settings.GROQ_API_KEY)
        self.tavily_client = TavilyClient(api_key=settings.TAVILY_API_KEY)
    
    def process_query(self, user_query):
        """
        ë©”ì¸ ì²˜ë¦¬ ë¡œì§
        """
        print(f"[1/5] ğŸ“ ì§ˆë¬¸ ë°›ìŒ: {user_query}")
        
        # 1. ì›¹ ê²€ìƒ‰
        search_results = self.search_official_docs(user_query)
        print(f"[2/5] ğŸ” ê²€ìƒ‰ ì™„ë£Œ: {len(search_results.get('results', []))}ê°œ ê²°ê³¼")
        
        # 2. AI ë‹µë³€ ìƒì„±
        ai_answer = self.generate_answer(user_query, search_results)
        print(f"[3/5] ğŸ¤– AI ë‹µë³€ ìƒì„± ì™„ë£Œ ({len(ai_answer)}ì)")
        
        # 3. íƒœê·¸ ìë™ ì¶”ì¶œ
        tag_names = self.extract_tags(user_query, ai_answer)
        print(f"[4/5] ğŸ·ï¸  íƒœê·¸ ì¶”ì¶œ ì™„ë£Œ: {tag_names}")
        
        # 4. ë§ˆí¬ë‹¤ìš´ ë³€í™˜
        markdown = self.convert_to_markdown(user_query, ai_answer, search_results)
        print(f"[5/5] ğŸ“„ ë§ˆí¬ë‹¤ìš´ ë³€í™˜ ì™„ë£Œ ({len(markdown)}ì)")
        
        # 5. DB ì €ì¥
        # 5-1. LearningLog ìƒì„±
        log = LearningLog.objects.create(
            query=user_query,
            ai_response=ai_answer,
            markdown_content=markdown,
        )
        
        # 5-2. Reference ìƒì„± ë° ì—°ê²°
        for result in search_results.get('results', []):
            ref, created = Reference.objects.get_or_create(
                url=result.get('url', ''),
                defaults={
                    'title': result.get('title', 'Untitled'),
                    'excerpt': result.get('content', '')[:500],  # 500ìë¡œ ì œí•œ
                    'source_type': self._determine_source_type(result.get('url', '')),
                }
            )
            log.references.add(ref)
            if created:
                print(f"  ğŸ“š ìƒˆ ë ˆí¼ëŸ°ìŠ¤ ìƒì„±: {ref.title}")
        
        # 5-3. Tag ìƒì„± ë° ì—°ê²°
        for tag_name in tag_names:
            tag, created = Tag.objects.get_or_create(
                name=tag_name,
                defaults={'slug': slugify(tag_name)}
            )
            log.tags.add(tag)
            if created:
                print(f"  ğŸ·ï¸  ìƒˆ íƒœê·¸ ìƒì„±: {tag.name}")
        
        print(f"âœ… ì €ì¥ ì™„ë£Œ! ID: {log.id}")
        return log
    
    def _determine_source_type(self, url):
        """
        URLì„ ë¶„ì„í•´ì„œ ì¶œì²˜ ìœ í˜• ê²°ì •
        """
        url_lower = url.lower()
        
        if 'stackoverflow.com' in url_lower:
            return 'stackoverflow'
        elif 'github.com' in url_lower:
            return 'github'
        elif any(domain in url_lower for domain in ['docs.', 'documentation', 'doc.']):
            return 'official'
        elif any(domain in url_lower for domain in ['blog', 'medium.com', 'dev.to']):
            return 'blog'
        else:
            return 'other'
    
    def search_official_docs(self, query):
        """
        Tavily APIë¡œ ê³µì‹ ë¬¸ì„œ ê²€ìƒ‰
        """
        try:
            results = self.tavily_client.search(
                query=query,
                search_depth="advanced",
                max_results=5,
                include_domains=[
                    "docs.docker.com",
                    "docs.python.org",
                    "docs.djangoproject.com",
                    "github.com",
                ]
            )
            return results
        except Exception as e:
            print(f"âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return {'results': []}
    
    def generate_answer(self, query, search_results):
        """
        Groq APIë¡œ AI ë‹µë³€ ìƒì„±
        """
        # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…
        context = "\n\n".join([
            f"ì¶œì²˜: {r.get('url', 'N/A')}\në‚´ìš©: {r.get('content', '')[:400]}"
            for r in search_results.get('results', [])[:3]  # ìƒìœ„ 3ê°œë§Œ
        ])
        
        prompt = f"""
                ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ì •í™•í•œ ê°œë°œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

                ì‚¬ìš©ì ì§ˆë¬¸: {query}

                ì°¸ê³  ìë£Œ:
                {context if context else "ì°¸ê³  ìë£Œ ì—†ìŒ"}

                ìœ„ ì°¸ê³  ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•œ ëª…í™•í•˜ê³  ìƒì„¸í•œ ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

                ìš”êµ¬ì‚¬í•­:
                - í•œêµ­ì–´ë¡œ ì‘ì„±
                - ê¸°ìˆ ì ìœ¼ë¡œ ì •í™•í•˜ê²Œ
                - ì´ˆë³´ìë„ ì´í•´í•  ìˆ˜ ìˆê²Œ ì„¤ëª…
                - ê°€ëŠ¥í•˜ë©´ ì½”ë“œ ì˜ˆì‹œ í¬í•¨
                - ê°„ê²°í•˜ì§€ë§Œ í•µì‹¬ì€ ë¹ ëœ¨ë¦¬ì§€ ì•Šê²Œ
            """
        
        try:
            response = self.groq_client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7, # ë‹µë³€ ë§íˆ¬ì˜ ë³€ë™ì„±
                max_tokens=2000 # ìµœëŒ€ ê¸€ì ìˆ˜, ìµœëŒ“ê°’ 16384
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            print(f"âŒ AI ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {e}")
            return "ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def extract_tags(self, query, ai_response):
        """
        Groq APIë¡œ íƒœê·¸ ìë™ ì¶”ì¶œ
        """
        prompt = f"""
            ë‹¤ìŒ ê°œë°œ ì§ˆë¬¸ê³¼ ë‹µë³€ì—ì„œ í•µì‹¬ ê¸°ìˆ  íƒœê·¸ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

            ì§ˆë¬¸: {query}
            ë‹µë³€: {ai_response[:500]}

            ê·œì¹™:
            - ì •í™•íˆ 3~5ê°œì˜ íƒœê·¸ë§Œ ì¶”ì¶œ
            - ëª¨ë‘ ì†Œë¬¸ì, ì˜ì–´ë§Œ ì‚¬ìš©
            - ì‰¼í‘œë¡œ êµ¬ë¶„
            - ê¸°ìˆ ëª…, ë„êµ¬ëª…, í•µì‹¬ ê°œë…ë§Œ í¬í•¨
            - ë¶ˆí•„ìš”í•œ ë‹¨ì–´ ì œì™¸ (ì˜ˆ: "how", "what", "difference")
            - ê³µë°±ì€ í•˜ì´í”ˆ(-)ìœ¼ë¡œ ëŒ€ì²´

            ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ: docker, network, bridge-mode, container

            íƒœê·¸:"""
        
        try:
            response = self.groq_client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.2,  # ë‚®ì€ temperatureë¡œ ì¼ê´€ì„± í™•ë³´
                max_tokens=50
            )
            
            tags_text = response.choices[0].message.content.strip()
            
            # íŒŒì‹± ë° ì •ì œ
            tags = [
                tag.strip().lower().replace(' ', '-')
                for tag in tags_text.split(',')
                if tag.strip() and len(tag.strip()) > 1
            ]
            
            return tags[:5]  # ìµœëŒ€ 5ê°œ
            
        except Exception as e:
            print(f"âŒ íƒœê·¸ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            # ì‹¤íŒ¨ ì‹œ ê°„ë‹¨íˆ ì§ˆë¬¸ì—ì„œ ì¶”ì¶œ
            return self._fallback_tag_extraction(query)
    
    def _fallback_tag_extraction(self, query):
        """
        íƒœê·¸ ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ ë°©ë²•
        """
        common_terms = [
            'docker', 'python', 'javascript', 'react', 'django',
            'api', 'database', 'network', 'kubernetes', 'git'
        ]
        
        query_lower = query.lower()
        tags = [term for term in common_terms if term in query_lower]
        
        return tags[:3] if tags else ['general']
    
    def convert_to_markdown(self, query, answer, search_results):
        """
        Groq APIë¡œ ë…¸ì…˜ ìŠ¤íƒ€ì¼ ë§ˆí¬ë‹¤ìš´ ë³€í™˜
        """
        refs = "\n".join([
            f"- [{r.get('title', 'N/A')}]({r.get('url', '')})"
            for r in search_results.get('results', [])
        ])
        
        prompt = f"""
            ë‹¤ìŒ ë‚´ìš©ì„ ë…¸ì…˜ ìŠ¤íƒ€ì¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”:

            ì§ˆë¬¸: {query}

            ë‹µë³€:
            {answer}

            ì°¸ê³  ìë£Œ:
            {refs if refs else "ì—†ìŒ"}

            ìš”êµ¬ì‚¬í•­:
            - ì œëª©ì€ ## ì§ˆë¬¸ í˜•ì‹ìœ¼ë¡œ
            - í•µì‹¬ ë‚´ìš©ì€ ëª…í™•í•˜ê²Œ êµ¬ì¡°í™”
            - ì°¨ì´ì ì´ë‚˜ ë¹„êµëŠ” í‘œ(table) ì‚¬ìš©
            - ì½”ë“œ ì˜ˆì‹œëŠ” ì ì ˆí•œ ì–¸ì–´ë¡œ ```ì–¸ì–´ ì½”ë“œë¸”ë¡``` ì‚¬ìš©
            - ì°¸ê³  ìë£ŒëŠ” ë§¨ ì•„ë˜ "## ì°¸ê³  ìë£Œ" ì„¹ì…˜ì—
            - ë…¸ì…˜ì— ë°”ë¡œ ë³µì‚¬/ë¶™ì—¬ë„£ê¸° ê°€ëŠ¥í•˜ê²Œ
            - ì´ëª¨ì§€ ì ì ˆíˆ ì‚¬ìš©

            ì¶œë ¥:"""
        
        try:
            response = self.groq_client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.5,
                max_tokens=3000
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            print(f"âŒ ë§ˆí¬ë‹¤ìš´ ë³€í™˜ ì˜¤ë¥˜: {e}")
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í¬ë§·
            return f"## {query}\n\n{answer}\n\n## ì°¸ê³  ìë£Œ\n{refs}"